2024-10-29 13:33:55,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-29 13:33:55,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-29 13:33:55,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-29 13:33:55,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-29 13:46:55,614:INFO:PyCaret ClassificationExperiment
2024-10-29 13:46:55,614:INFO:Logging name: pancreas
2024-10-29 13:46:55,614:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-29 13:46:55,624:INFO:version 3.3.2
2024-10-29 13:46:55,624:INFO:Initializing setup()
2024-10-29 13:46:55,624:INFO:self.USI: e8aa
2024-10-29 13:46:55,624:INFO:self._variable_keys: {'memory', 'gpu_n_jobs_param', 'exp_id', 'y_train', 'USI', 'X_test', 'idx', 'n_jobs_param', 'fold_groups_param', 'fold_shuffle_param', 'pipeline', 'y_test', 'fix_imbalance', 'target_param', 'X_train', 'is_multiclass', 'data', 'fold_generator', 'y', 'X', 'log_plots_param', '_ml_usecase', 'html_param', 'gpu_param', 'exp_name_log', '_available_plots', 'seed', 'logging_param'}
2024-10-29 13:46:55,624:INFO:Checking environment
2024-10-29 13:46:55,625:INFO:python_version: 3.9.19
2024-10-29 13:46:55,625:INFO:python_build: ('main', 'May  6 2024 20:12:36')
2024-10-29 13:46:55,625:INFO:machine: AMD64
2024-10-29 13:46:55,625:INFO:platform: Windows-10-10.0.22631-SP0
2024-10-29 13:46:55,629:INFO:Memory: svmem(total=14877265920, available=2493448192, percent=83.2, used=12383817728, free=2493448192)
2024-10-29 13:46:55,629:INFO:Physical Core: 8
2024-10-29 13:46:55,629:INFO:Logical Core: 16
2024-10-29 13:46:55,629:INFO:Checking libraries
2024-10-29 13:46:55,629:INFO:System:
2024-10-29 13:46:55,629:INFO:    python: 3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]
2024-10-29 13:46:55,629:INFO:executable: c:\Users\arunm\.conda\envs\arun\python.exe
2024-10-29 13:46:55,629:INFO:   machine: Windows-10-10.0.22631-SP0
2024-10-29 13:46:55,630:INFO:PyCaret required dependencies:
2024-10-29 13:46:55,715:INFO:                 pip: 24.2
2024-10-29 13:46:55,715:INFO:          setuptools: 65.5.0
2024-10-29 13:46:55,716:INFO:             pycaret: 3.3.2
2024-10-29 13:46:55,716:INFO:             IPython: 8.18.1
2024-10-29 13:46:55,716:INFO:          ipywidgets: 8.1.3
2024-10-29 13:46:55,716:INFO:                tqdm: 4.66.2
2024-10-29 13:46:55,716:INFO:               numpy: 1.24.4
2024-10-29 13:46:55,716:INFO:              pandas: 2.1.4
2024-10-29 13:46:55,716:INFO:              jinja2: 3.1.4
2024-10-29 13:46:55,716:INFO:               scipy: 1.11.4
2024-10-29 13:46:55,716:INFO:              joblib: 1.3.2
2024-10-29 13:46:55,716:INFO:             sklearn: 1.4.2
2024-10-29 13:46:55,716:INFO:                pyod: 2.0.2
2024-10-29 13:46:55,716:INFO:            imblearn: 0.12.4
2024-10-29 13:46:55,716:INFO:   category_encoders: 2.6.4
2024-10-29 13:46:55,716:INFO:            lightgbm: 4.5.0
2024-10-29 13:46:55,716:INFO:               numba: 0.60.0
2024-10-29 13:46:55,716:INFO:            requests: 2.32.3
2024-10-29 13:46:55,716:INFO:          matplotlib: 3.6.2
2024-10-29 13:46:55,716:INFO:          scikitplot: 0.3.7
2024-10-29 13:46:55,716:INFO:         yellowbrick: 1.5
2024-10-29 13:46:55,716:INFO:              plotly: 5.23.0
2024-10-29 13:46:55,716:INFO:    plotly-resampler: Not installed
2024-10-29 13:46:55,716:INFO:             kaleido: 0.2.1
2024-10-29 13:46:55,716:INFO:           schemdraw: 0.15
2024-10-29 13:46:55,716:INFO:         statsmodels: 0.14.4
2024-10-29 13:46:55,716:INFO:              sktime: 0.26.0
2024-10-29 13:46:55,716:INFO:               tbats: 1.1.3
2024-10-29 13:46:55,716:INFO:            pmdarima: 2.0.4
2024-10-29 13:46:55,716:INFO:              psutil: 6.0.0
2024-10-29 13:46:55,716:INFO:          markupsafe: 2.1.5
2024-10-29 13:46:55,716:INFO:             pickle5: Not installed
2024-10-29 13:46:55,716:INFO:         cloudpickle: 3.0.0
2024-10-29 13:46:55,716:INFO:         deprecation: 2.1.0
2024-10-29 13:46:55,717:INFO:              xxhash: 3.5.0
2024-10-29 13:46:55,717:INFO:           wurlitzer: Not installed
2024-10-29 13:46:55,717:INFO:PyCaret optional dependencies:
2024-10-29 13:46:56,601:INFO:                shap: 0.46.0
2024-10-29 13:46:56,601:INFO:           interpret: 0.6.3
2024-10-29 13:46:56,601:INFO:                umap: Not installed
2024-10-29 13:46:56,601:INFO:     ydata_profiling: Not installed
2024-10-29 13:46:56,601:INFO:  explainerdashboard: Not installed
2024-10-29 13:46:56,601:INFO:             autoviz: Not installed
2024-10-29 13:46:56,601:INFO:           fairlearn: Not installed
2024-10-29 13:46:56,601:INFO:          deepchecks: Not installed
2024-10-29 13:46:56,601:INFO:             xgboost: 2.1.1
2024-10-29 13:46:56,601:INFO:            catboost: Not installed
2024-10-29 13:46:56,601:INFO:              kmodes: Not installed
2024-10-29 13:46:56,601:INFO:             mlxtend: Not installed
2024-10-29 13:46:56,601:INFO:       statsforecast: Not installed
2024-10-29 13:46:56,601:INFO:        tune_sklearn: Not installed
2024-10-29 13:46:56,601:INFO:                 ray: Not installed
2024-10-29 13:46:56,601:INFO:            hyperopt: Not installed
2024-10-29 13:46:56,601:INFO:              optuna: Not installed
2024-10-29 13:46:56,601:INFO:               skopt: Not installed
2024-10-29 13:46:56,601:INFO:              mlflow: Not installed
2024-10-29 13:46:56,602:INFO:              gradio: Not installed
2024-10-29 13:46:56,602:INFO:             fastapi: 0.111.0
2024-10-29 13:46:56,602:INFO:             uvicorn: 0.30.6
2024-10-29 13:46:56,602:INFO:              m2cgen: Not installed
2024-10-29 13:46:56,602:INFO:           evidently: Not installed
2024-10-29 13:46:56,602:INFO:               fugue: Not installed
2024-10-29 13:46:56,602:INFO:           streamlit: Not installed
2024-10-29 13:46:56,602:INFO:             prophet: Not installed
2024-10-29 13:46:56,602:INFO:None
2024-10-29 13:46:56,602:INFO:Set up data.
2024-10-29 13:46:56,606:INFO:Set up folding strategy.
2024-10-29 13:46:56,606:INFO:Set up train/test split.
2024-10-29 13:46:56,629:INFO:Set up index.
2024-10-29 13:46:56,629:INFO:Assigning column types.
2024-10-29 13:46:56,632:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-29 13:46:56,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-29 13:46:56,670:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-29 13:46:56,696:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:56,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:56,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-29 13:46:56,733:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-29 13:46:56,755:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:56,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:56,757:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-29 13:46:56,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-29 13:46:56,814:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:56,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:56,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-29 13:46:56,873:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:56,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:56,876:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-10-29 13:46:56,933:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:56,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:56,990:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:56,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:56,995:INFO:Preparing preprocessing pipeline...
2024-10-29 13:46:56,996:INFO:Set up label encoding.
2024-10-29 13:46:56,996:INFO:Set up simple imputation.
2024-10-29 13:46:56,998:INFO:Set up encoding of ordinal features.
2024-10-29 13:46:56,999:INFO:Set up encoding of categorical features.
2024-10-29 13:46:56,999:INFO:Set up feature normalization.
2024-10-29 13:46:57,079:INFO:Finished creating preprocessing pipeline.
2024-10-29 13:46:57,091:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\arunm\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'plasma_CA19_9',
                                             'creatinine', 'LYVE1', 'REG1B',
                                             'TFF1', 'REG1A'],
                                    transformer=SimpleImputer(add_ind...
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-10-29 13:46:57,091:INFO:Creating final display dataframe.
2024-10-29 13:46:57,253:INFO:Setup _display_container:                     Description             Value
0                    Session id                71
1                        Target         diagnosis
2                   Target type        Multiclass
3                Target mapping  1: 0, 2: 1, 3: 2
4           Original data shape         (590, 13)
5        Transformed data shape          (590, 9)
6   Transformed train set shape          (472, 9)
7    Transformed test set shape          (118, 9)
8               Ignore features                 4
9              Numeric features                 7
10         Categorical features                 1
11     Rows with missing values            100.0%
12                   Preprocess              True
13              Imputation type            simple
14           Numeric imputation            median
15       Categorical imputation              mode
16     Maximum one-hot encoding                25
17              Encoding method              None
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name          pancreas
26                          USI              e8aa
2024-10-29 13:46:57,316:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:57,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:57,375:INFO:Soft dependency imported: xgboost: 2.1.1
2024-10-29 13:46:57,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-29 13:46:57,378:INFO:setup() successfully completed in 1.77s...............
2024-10-29 13:47:10,181:INFO:Initializing compare_models()
2024-10-29 13:47:10,181:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-10-29 13:47:10,181:INFO:Checking exceptions
2024-10-29 13:47:10,184:INFO:Preparing display monitor
2024-10-29 13:47:10,206:INFO:Initializing Logistic Regression
2024-10-29 13:47:10,206:INFO:Total runtime is 0.0 minutes
2024-10-29 13:47:10,210:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:10,210:INFO:Initializing create_model()
2024-10-29 13:47:10,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:10,210:INFO:Checking exceptions
2024-10-29 13:47:10,210:INFO:Importing libraries
2024-10-29 13:47:10,210:INFO:Copying training dataset
2024-10-29 13:47:10,214:INFO:Defining folds
2024-10-29 13:47:10,214:INFO:Declaring metric variables
2024-10-29 13:47:10,217:INFO:Importing untrained model
2024-10-29 13:47:10,220:INFO:Logistic Regression Imported successfully
2024-10-29 13:47:10,226:INFO:Starting cross validation
2024-10-29 13:47:10,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:14,107:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,107:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,109:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,110:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,110:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,112:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,113:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,114:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,114:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,114:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,117:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,117:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,119:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,120:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,120:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,120:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,122:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,122:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,124:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,125:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,127:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,128:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,129:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,129:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,133:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,133:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,136:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,137:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,137:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,138:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,140:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,141:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,144:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:14,148:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,153:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,157:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,171:INFO:Calculating mean and std
2024-10-29 13:47:14,173:INFO:Creating metrics dataframe
2024-10-29 13:47:14,178:INFO:Uploading results into container
2024-10-29 13:47:14,179:INFO:Uploading model into container now
2024-10-29 13:47:14,180:INFO:_master_model_container: 1
2024-10-29 13:47:14,181:INFO:_display_container: 2
2024-10-29 13:47:14,182:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=71, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-10-29 13:47:14,182:INFO:create_model() successfully completed......................................
2024-10-29 13:47:14,489:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:14,489:INFO:Creating metrics dataframe
2024-10-29 13:47:14,494:INFO:Initializing K Neighbors Classifier
2024-10-29 13:47:14,494:INFO:Total runtime is 0.07147020896275838 minutes
2024-10-29 13:47:14,497:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:14,497:INFO:Initializing create_model()
2024-10-29 13:47:14,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:14,498:INFO:Checking exceptions
2024-10-29 13:47:14,498:INFO:Importing libraries
2024-10-29 13:47:14,498:INFO:Copying training dataset
2024-10-29 13:47:14,502:INFO:Defining folds
2024-10-29 13:47:14,502:INFO:Declaring metric variables
2024-10-29 13:47:14,504:INFO:Importing untrained model
2024-10-29 13:47:14,507:INFO:K Neighbors Classifier Imported successfully
2024-10-29 13:47:14,514:INFO:Starting cross validation
2024-10-29 13:47:14,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:14,673:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,673:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,676:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,676:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,679:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,679:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,689:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,690:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,692:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,692:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,695:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:14,695:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,066:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,067:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,068:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,068:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,068:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,069:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,069:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,070:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,070:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,070:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,070:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,071:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,072:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,072:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,083:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,085:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,087:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,108:INFO:Calculating mean and std
2024-10-29 13:47:17,110:INFO:Creating metrics dataframe
2024-10-29 13:47:17,113:INFO:Uploading results into container
2024-10-29 13:47:17,115:INFO:Uploading model into container now
2024-10-29 13:47:17,116:INFO:_master_model_container: 2
2024-10-29 13:47:17,116:INFO:_display_container: 2
2024-10-29 13:47:17,117:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-10-29 13:47:17,117:INFO:create_model() successfully completed......................................
2024-10-29 13:47:17,337:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:17,337:INFO:Creating metrics dataframe
2024-10-29 13:47:17,343:INFO:Initializing Naive Bayes
2024-10-29 13:47:17,344:INFO:Total runtime is 0.11896570523579915 minutes
2024-10-29 13:47:17,345:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:17,346:INFO:Initializing create_model()
2024-10-29 13:47:17,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:17,346:INFO:Checking exceptions
2024-10-29 13:47:17,346:INFO:Importing libraries
2024-10-29 13:47:17,346:INFO:Copying training dataset
2024-10-29 13:47:17,351:INFO:Defining folds
2024-10-29 13:47:17,351:INFO:Declaring metric variables
2024-10-29 13:47:17,353:INFO:Importing untrained model
2024-10-29 13:47:17,355:INFO:Naive Bayes Imported successfully
2024-10-29 13:47:17,360:INFO:Starting cross validation
2024-10-29 13:47:17,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:17,433:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,435:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,436:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,437:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,438:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,439:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,440:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,440:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,442:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,443:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,445:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,445:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,445:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,447:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,447:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,447:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,448:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,449:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,449:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,449:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,451:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,452:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,453:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,454:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,455:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,455:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,456:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,457:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,458:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,465:INFO:Calculating mean and std
2024-10-29 13:47:17,466:INFO:Creating metrics dataframe
2024-10-29 13:47:17,468:INFO:Uploading results into container
2024-10-29 13:47:17,468:INFO:Uploading model into container now
2024-10-29 13:47:17,469:INFO:_master_model_container: 3
2024-10-29 13:47:17,469:INFO:_display_container: 2
2024-10-29 13:47:17,469:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-10-29 13:47:17,469:INFO:create_model() successfully completed......................................
2024-10-29 13:47:17,637:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:17,638:INFO:Creating metrics dataframe
2024-10-29 13:47:17,643:INFO:Initializing Decision Tree Classifier
2024-10-29 13:47:17,643:INFO:Total runtime is 0.1239487608273824 minutes
2024-10-29 13:47:17,645:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:17,646:INFO:Initializing create_model()
2024-10-29 13:47:17,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:17,646:INFO:Checking exceptions
2024-10-29 13:47:17,646:INFO:Importing libraries
2024-10-29 13:47:17,646:INFO:Copying training dataset
2024-10-29 13:47:17,650:INFO:Defining folds
2024-10-29 13:47:17,650:INFO:Declaring metric variables
2024-10-29 13:47:17,652:INFO:Importing untrained model
2024-10-29 13:47:17,658:INFO:Decision Tree Classifier Imported successfully
2024-10-29 13:47:17,666:INFO:Starting cross validation
2024-10-29 13:47:17,669:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:17,764:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,765:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,766:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,768:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,768:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,768:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,771:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,772:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,772:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,772:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,773:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,773:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,774:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,774:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,774:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,774:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,775:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,775:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,775:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,776:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,777:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,777:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,778:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,780:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:17,793:INFO:Calculating mean and std
2024-10-29 13:47:17,794:INFO:Creating metrics dataframe
2024-10-29 13:47:17,795:INFO:Uploading results into container
2024-10-29 13:47:17,795:INFO:Uploading model into container now
2024-10-29 13:47:17,796:INFO:_master_model_container: 4
2024-10-29 13:47:17,796:INFO:_display_container: 2
2024-10-29 13:47:17,796:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=71, splitter='best')
2024-10-29 13:47:17,796:INFO:create_model() successfully completed......................................
2024-10-29 13:47:17,963:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:17,963:INFO:Creating metrics dataframe
2024-10-29 13:47:17,968:INFO:Initializing SVM - Linear Kernel
2024-10-29 13:47:17,968:INFO:Total runtime is 0.12937735716501872 minutes
2024-10-29 13:47:17,971:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:17,971:INFO:Initializing create_model()
2024-10-29 13:47:17,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:17,971:INFO:Checking exceptions
2024-10-29 13:47:17,971:INFO:Importing libraries
2024-10-29 13:47:17,971:INFO:Copying training dataset
2024-10-29 13:47:17,975:INFO:Defining folds
2024-10-29 13:47:17,975:INFO:Declaring metric variables
2024-10-29 13:47:17,979:INFO:Importing untrained model
2024-10-29 13:47:17,981:INFO:SVM - Linear Kernel Imported successfully
2024-10-29 13:47:17,987:INFO:Starting cross validation
2024-10-29 13:47:17,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:18,099:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,099:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,100:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,100:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,102:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,102:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,102:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,104:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,104:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,104:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,104:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,104:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,104:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,104:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,105:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,105:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,105:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,105:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,105:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,106:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,106:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,106:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,106:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,107:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,107:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,107:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,107:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,108:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,108:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,108:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,109:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,109:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,109:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,110:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,110:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,111:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,112:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,114:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,114:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,121:INFO:Calculating mean and std
2024-10-29 13:47:18,122:INFO:Creating metrics dataframe
2024-10-29 13:47:18,125:INFO:Uploading results into container
2024-10-29 13:47:18,126:INFO:Uploading model into container now
2024-10-29 13:47:18,126:INFO:_master_model_container: 5
2024-10-29 13:47:18,126:INFO:_display_container: 2
2024-10-29 13:47:18,127:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=71, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-10-29 13:47:18,127:INFO:create_model() successfully completed......................................
2024-10-29 13:47:18,286:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:18,287:INFO:Creating metrics dataframe
2024-10-29 13:47:18,293:INFO:Initializing Ridge Classifier
2024-10-29 13:47:18,293:INFO:Total runtime is 0.13478403488794963 minutes
2024-10-29 13:47:18,295:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:18,295:INFO:Initializing create_model()
2024-10-29 13:47:18,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:18,295:INFO:Checking exceptions
2024-10-29 13:47:18,296:INFO:Importing libraries
2024-10-29 13:47:18,296:INFO:Copying training dataset
2024-10-29 13:47:18,300:INFO:Defining folds
2024-10-29 13:47:18,300:INFO:Declaring metric variables
2024-10-29 13:47:18,302:INFO:Importing untrained model
2024-10-29 13:47:18,306:INFO:Ridge Classifier Imported successfully
2024-10-29 13:47:18,312:INFO:Starting cross validation
2024-10-29 13:47:18,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:18,386:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,387:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,387:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,387:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,388:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,389:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,389:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,389:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,390:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,390:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,390:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,390:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,391:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,391:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,392:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,392:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,393:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,393:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,394:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,394:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,395:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,395:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,395:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,396:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,397:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,397:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,397:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,397:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,398:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,398:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,399:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,400:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,400:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,401:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,402:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,402:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,404:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:18,405:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,407:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,408:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,418:INFO:Calculating mean and std
2024-10-29 13:47:18,419:INFO:Creating metrics dataframe
2024-10-29 13:47:18,420:INFO:Uploading results into container
2024-10-29 13:47:18,420:INFO:Uploading model into container now
2024-10-29 13:47:18,421:INFO:_master_model_container: 6
2024-10-29 13:47:18,421:INFO:_display_container: 2
2024-10-29 13:47:18,421:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=71, solver='auto',
                tol=0.0001)
2024-10-29 13:47:18,421:INFO:create_model() successfully completed......................................
2024-10-29 13:47:18,593:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:18,594:INFO:Creating metrics dataframe
2024-10-29 13:47:18,604:INFO:Initializing Random Forest Classifier
2024-10-29 13:47:18,604:INFO:Total runtime is 0.13996331691741942 minutes
2024-10-29 13:47:18,607:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:18,607:INFO:Initializing create_model()
2024-10-29 13:47:18,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:18,607:INFO:Checking exceptions
2024-10-29 13:47:18,607:INFO:Importing libraries
2024-10-29 13:47:18,608:INFO:Copying training dataset
2024-10-29 13:47:18,612:INFO:Defining folds
2024-10-29 13:47:18,612:INFO:Declaring metric variables
2024-10-29 13:47:18,615:INFO:Importing untrained model
2024-10-29 13:47:18,620:INFO:Random Forest Classifier Imported successfully
2024-10-29 13:47:18,629:INFO:Starting cross validation
2024-10-29 13:47:18,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:18,925:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,927:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,930:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,939:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,940:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,940:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,942:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,942:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,943:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,944:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,944:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,945:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,953:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,954:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,954:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,955:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,955:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,955:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,956:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,957:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,957:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,957:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,957:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,967:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,967:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,969:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,969:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,971:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,971:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:18,978:INFO:Calculating mean and std
2024-10-29 13:47:18,979:INFO:Creating metrics dataframe
2024-10-29 13:47:18,981:INFO:Uploading results into container
2024-10-29 13:47:18,982:INFO:Uploading model into container now
2024-10-29 13:47:18,982:INFO:_master_model_container: 7
2024-10-29 13:47:18,982:INFO:_display_container: 2
2024-10-29 13:47:18,983:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=71, verbose=0,
                       warm_start=False)
2024-10-29 13:47:18,983:INFO:create_model() successfully completed......................................
2024-10-29 13:47:19,152:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:19,152:INFO:Creating metrics dataframe
2024-10-29 13:47:19,159:INFO:Initializing Quadratic Discriminant Analysis
2024-10-29 13:47:19,159:INFO:Total runtime is 0.149225648244222 minutes
2024-10-29 13:47:19,161:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:19,162:INFO:Initializing create_model()
2024-10-29 13:47:19,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:19,162:INFO:Checking exceptions
2024-10-29 13:47:19,162:INFO:Importing libraries
2024-10-29 13:47:19,162:INFO:Copying training dataset
2024-10-29 13:47:19,166:INFO:Defining folds
2024-10-29 13:47:19,166:INFO:Declaring metric variables
2024-10-29 13:47:19,169:INFO:Importing untrained model
2024-10-29 13:47:19,172:INFO:Quadratic Discriminant Analysis Imported successfully
2024-10-29 13:47:19,177:INFO:Starting cross validation
2024-10-29 13:47:19,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:19,262:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,263:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,263:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,263:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,263:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,264:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,264:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,265:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,265:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,265:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,267:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,267:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,267:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,267:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,268:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,269:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,269:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,269:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,270:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,270:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,272:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,272:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,272:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,273:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,273:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,273:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,274:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,276:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,276:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,276:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,276:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,278:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,278:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,278:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,280:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,280:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,281:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,282:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,285:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,291:INFO:Calculating mean and std
2024-10-29 13:47:19,292:INFO:Creating metrics dataframe
2024-10-29 13:47:19,294:INFO:Uploading results into container
2024-10-29 13:47:19,295:INFO:Uploading model into container now
2024-10-29 13:47:19,295:INFO:_master_model_container: 8
2024-10-29 13:47:19,295:INFO:_display_container: 2
2024-10-29 13:47:19,295:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-10-29 13:47:19,295:INFO:create_model() successfully completed......................................
2024-10-29 13:47:19,485:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:19,486:INFO:Creating metrics dataframe
2024-10-29 13:47:19,493:INFO:Initializing Ada Boost Classifier
2024-10-29 13:47:19,493:INFO:Total runtime is 0.15479166507720946 minutes
2024-10-29 13:47:19,496:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:19,496:INFO:Initializing create_model()
2024-10-29 13:47:19,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:19,497:INFO:Checking exceptions
2024-10-29 13:47:19,497:INFO:Importing libraries
2024-10-29 13:47:19,497:INFO:Copying training dataset
2024-10-29 13:47:19,501:INFO:Defining folds
2024-10-29 13:47:19,501:INFO:Declaring metric variables
2024-10-29 13:47:19,505:INFO:Importing untrained model
2024-10-29 13:47:19,508:INFO:Ada Boost Classifier Imported successfully
2024-10-29 13:47:19,514:INFO:Starting cross validation
2024-10-29 13:47:19,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:19,578:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,579:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,580:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,581:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,582:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,584:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,585:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,589:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,595:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,598:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-29 13:47:19,746:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,747:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,751:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,751:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,753:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,754:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,755:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,757:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,757:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,757:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,759:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,760:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,760:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,762:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,762:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,763:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,763:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,763:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,764:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,765:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,765:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,766:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,768:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,769:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,769:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,770:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,771:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,771:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,773:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:19,773:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,773:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,773:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,774:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,775:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,775:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,776:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,776:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,778:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:19,793:INFO:Calculating mean and std
2024-10-29 13:47:19,794:INFO:Creating metrics dataframe
2024-10-29 13:47:19,796:INFO:Uploading results into container
2024-10-29 13:47:19,796:INFO:Uploading model into container now
2024-10-29 13:47:19,797:INFO:_master_model_container: 9
2024-10-29 13:47:19,797:INFO:_display_container: 2
2024-10-29 13:47:19,797:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=71)
2024-10-29 13:47:19,797:INFO:create_model() successfully completed......................................
2024-10-29 13:47:19,998:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:19,998:INFO:Creating metrics dataframe
2024-10-29 13:47:20,005:INFO:Initializing Gradient Boosting Classifier
2024-10-29 13:47:20,005:INFO:Total runtime is 0.16331705252329506 minutes
2024-10-29 13:47:20,008:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:20,008:INFO:Initializing create_model()
2024-10-29 13:47:20,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:20,008:INFO:Checking exceptions
2024-10-29 13:47:20,008:INFO:Importing libraries
2024-10-29 13:47:20,008:INFO:Copying training dataset
2024-10-29 13:47:20,012:INFO:Defining folds
2024-10-29 13:47:20,012:INFO:Declaring metric variables
2024-10-29 13:47:20,015:INFO:Importing untrained model
2024-10-29 13:47:20,018:INFO:Gradient Boosting Classifier Imported successfully
2024-10-29 13:47:20,023:INFO:Starting cross validation
2024-10-29 13:47:20,025:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:20,559:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,561:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,563:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,565:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,579:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,580:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,580:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,581:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,582:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,583:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,584:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,586:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,589:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,591:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,591:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,592:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,592:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,593:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,594:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,594:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,595:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,596:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,597:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,598:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,599:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,601:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,601:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,601:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,602:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,603:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,604:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,606:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,608:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,609:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,611:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,612:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,618:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,619:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,620:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,622:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,637:INFO:Calculating mean and std
2024-10-29 13:47:20,638:INFO:Creating metrics dataframe
2024-10-29 13:47:20,640:INFO:Uploading results into container
2024-10-29 13:47:20,640:INFO:Uploading model into container now
2024-10-29 13:47:20,641:INFO:_master_model_container: 10
2024-10-29 13:47:20,641:INFO:_display_container: 2
2024-10-29 13:47:20,641:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-29 13:47:20,642:INFO:create_model() successfully completed......................................
2024-10-29 13:47:20,810:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:20,810:INFO:Creating metrics dataframe
2024-10-29 13:47:20,818:INFO:Initializing Linear Discriminant Analysis
2024-10-29 13:47:20,818:INFO:Total runtime is 0.1768648266792297 minutes
2024-10-29 13:47:20,820:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:20,820:INFO:Initializing create_model()
2024-10-29 13:47:20,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:20,821:INFO:Checking exceptions
2024-10-29 13:47:20,821:INFO:Importing libraries
2024-10-29 13:47:20,821:INFO:Copying training dataset
2024-10-29 13:47:20,825:INFO:Defining folds
2024-10-29 13:47:20,825:INFO:Declaring metric variables
2024-10-29 13:47:20,828:INFO:Importing untrained model
2024-10-29 13:47:20,830:INFO:Linear Discriminant Analysis Imported successfully
2024-10-29 13:47:20,835:INFO:Starting cross validation
2024-10-29 13:47:20,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:20,915:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,916:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,917:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,917:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,918:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,918:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,919:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,919:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,920:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,920:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,921:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,921:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,921:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,922:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,922:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,922:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,923:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,923:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,923:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,923:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,923:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,923:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:20,923:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,924:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,924:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,925:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,925:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,926:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,926:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,927:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,927:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,928:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,928:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,928:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,928:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,929:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,929:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,930:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:20,935:INFO:Calculating mean and std
2024-10-29 13:47:20,936:INFO:Creating metrics dataframe
2024-10-29 13:47:20,937:INFO:Uploading results into container
2024-10-29 13:47:20,938:INFO:Uploading model into container now
2024-10-29 13:47:20,938:INFO:_master_model_container: 11
2024-10-29 13:47:20,938:INFO:_display_container: 2
2024-10-29 13:47:20,939:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-10-29 13:47:20,939:INFO:create_model() successfully completed......................................
2024-10-29 13:47:21,125:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:21,125:INFO:Creating metrics dataframe
2024-10-29 13:47:21,133:INFO:Initializing Extra Trees Classifier
2024-10-29 13:47:21,133:INFO:Total runtime is 0.1821197390556335 minutes
2024-10-29 13:47:21,136:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:21,137:INFO:Initializing create_model()
2024-10-29 13:47:21,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:21,137:INFO:Checking exceptions
2024-10-29 13:47:21,137:INFO:Importing libraries
2024-10-29 13:47:21,137:INFO:Copying training dataset
2024-10-29 13:47:21,140:INFO:Defining folds
2024-10-29 13:47:21,140:INFO:Declaring metric variables
2024-10-29 13:47:21,143:INFO:Importing untrained model
2024-10-29 13:47:21,147:INFO:Extra Trees Classifier Imported successfully
2024-10-29 13:47:21,152:INFO:Starting cross validation
2024-10-29 13:47:21,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:21,426:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,426:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,426:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,426:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,428:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,428:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,428:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,428:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,429:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,429:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,430:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,430:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,430:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,430:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,431:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,432:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,440:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,440:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,440:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,442:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,442:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,443:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,444:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,444:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,444:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,455:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,456:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,458:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:21,464:INFO:Calculating mean and std
2024-10-29 13:47:21,465:INFO:Creating metrics dataframe
2024-10-29 13:47:21,467:INFO:Uploading results into container
2024-10-29 13:47:21,468:INFO:Uploading model into container now
2024-10-29 13:47:21,468:INFO:_master_model_container: 12
2024-10-29 13:47:21,468:INFO:_display_container: 2
2024-10-29 13:47:21,469:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=71, verbose=0,
                     warm_start=False)
2024-10-29 13:47:21,469:INFO:create_model() successfully completed......................................
2024-10-29 13:47:21,648:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:21,648:INFO:Creating metrics dataframe
2024-10-29 13:47:21,656:INFO:Initializing Extreme Gradient Boosting
2024-10-29 13:47:21,656:INFO:Total runtime is 0.19083754221598304 minutes
2024-10-29 13:47:21,659:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:21,659:INFO:Initializing create_model()
2024-10-29 13:47:21,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:21,659:INFO:Checking exceptions
2024-10-29 13:47:21,659:INFO:Importing libraries
2024-10-29 13:47:21,659:INFO:Copying training dataset
2024-10-29 13:47:21,663:INFO:Defining folds
2024-10-29 13:47:21,663:INFO:Declaring metric variables
2024-10-29 13:47:21,667:INFO:Importing untrained model
2024-10-29 13:47:21,670:INFO:Extreme Gradient Boosting Imported successfully
2024-10-29 13:47:21,675:INFO:Starting cross validation
2024-10-29 13:47:21,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:22,562:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,564:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,566:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,589:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,591:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,595:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,599:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,601:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,605:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,605:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,607:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,607:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,609:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,609:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,609:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,610:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,611:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,611:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,613:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,613:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,613:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,617:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,618:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,619:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,620:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,621:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,622:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,627:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,628:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,630:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:22,635:INFO:Calculating mean and std
2024-10-29 13:47:22,636:INFO:Creating metrics dataframe
2024-10-29 13:47:22,638:INFO:Uploading results into container
2024-10-29 13:47:22,638:INFO:Uploading model into container now
2024-10-29 13:47:22,639:INFO:_master_model_container: 13
2024-10-29 13:47:22,639:INFO:_display_container: 2
2024-10-29 13:47:22,640:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-10-29 13:47:22,640:INFO:create_model() successfully completed......................................
2024-10-29 13:47:22,847:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:22,847:INFO:Creating metrics dataframe
2024-10-29 13:47:22,855:INFO:Initializing Light Gradient Boosting Machine
2024-10-29 13:47:22,855:INFO:Total runtime is 0.2108166138331095 minutes
2024-10-29 13:47:22,857:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:22,857:INFO:Initializing create_model()
2024-10-29 13:47:22,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:22,858:INFO:Checking exceptions
2024-10-29 13:47:22,858:INFO:Importing libraries
2024-10-29 13:47:22,858:INFO:Copying training dataset
2024-10-29 13:47:22,862:INFO:Defining folds
2024-10-29 13:47:22,862:INFO:Declaring metric variables
2024-10-29 13:47:22,864:INFO:Importing untrained model
2024-10-29 13:47:22,868:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-29 13:47:22,875:INFO:Starting cross validation
2024-10-29 13:47:22,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:23,727:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,730:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,733:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,748:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,748:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,751:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,752:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,754:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,755:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,755:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,759:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,762:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,798:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,802:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,805:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,813:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,816:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,818:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,819:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,821:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,824:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,844:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,847:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,850:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,864:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,867:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,870:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,933:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,936:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,938:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:23,947:INFO:Calculating mean and std
2024-10-29 13:47:23,948:INFO:Creating metrics dataframe
2024-10-29 13:47:23,951:INFO:Uploading results into container
2024-10-29 13:47:23,951:INFO:Uploading model into container now
2024-10-29 13:47:23,952:INFO:_master_model_container: 14
2024-10-29 13:47:23,952:INFO:_display_container: 2
2024-10-29 13:47:23,952:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=71, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-10-29 13:47:23,952:INFO:create_model() successfully completed......................................
2024-10-29 13:47:24,147:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:24,147:INFO:Creating metrics dataframe
2024-10-29 13:47:24,156:INFO:Initializing Dummy Classifier
2024-10-29 13:47:24,156:INFO:Total runtime is 0.2325056711832682 minutes
2024-10-29 13:47:24,158:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:24,158:INFO:Initializing create_model()
2024-10-29 13:47:24,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0FBB9F8B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:24,160:INFO:Checking exceptions
2024-10-29 13:47:24,160:INFO:Importing libraries
2024-10-29 13:47:24,160:INFO:Copying training dataset
2024-10-29 13:47:24,164:INFO:Defining folds
2024-10-29 13:47:24,164:INFO:Declaring metric variables
2024-10-29 13:47:24,168:INFO:Importing untrained model
2024-10-29 13:47:24,171:INFO:Dummy Classifier Imported successfully
2024-10-29 13:47:24,179:INFO:Starting cross validation
2024-10-29 13:47:24,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:24,294:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,296:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,297:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,297:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,299:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,299:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,302:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,302:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,302:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,302:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,303:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,304:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,305:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,307:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,308:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,309:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,311:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,313:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,314:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,314:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,315:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,315:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,317:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,317:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,318:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,318:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,319:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,319:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,319:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,320:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,320:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,321:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,321:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,321:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,322:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,322:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,323:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,327:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,328:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-29 13:47:24,328:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:24,339:INFO:Calculating mean and std
2024-10-29 13:47:24,340:INFO:Creating metrics dataframe
2024-10-29 13:47:24,342:INFO:Uploading results into container
2024-10-29 13:47:24,342:INFO:Uploading model into container now
2024-10-29 13:47:24,343:INFO:_master_model_container: 15
2024-10-29 13:47:24,343:INFO:_display_container: 2
2024-10-29 13:47:24,343:INFO:DummyClassifier(constant=None, random_state=71, strategy='prior')
2024-10-29 13:47:24,343:INFO:create_model() successfully completed......................................
2024-10-29 13:47:24,564:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:24,565:INFO:Creating metrics dataframe
2024-10-29 13:47:24,575:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-10-29 13:47:24,583:INFO:Initializing create_model()
2024-10-29 13:47:24,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:24,583:INFO:Checking exceptions
2024-10-29 13:47:24,585:INFO:Importing libraries
2024-10-29 13:47:24,585:INFO:Copying training dataset
2024-10-29 13:47:24,588:INFO:Defining folds
2024-10-29 13:47:24,588:INFO:Declaring metric variables
2024-10-29 13:47:24,588:INFO:Importing untrained model
2024-10-29 13:47:24,588:INFO:Declaring custom model
2024-10-29 13:47:24,588:INFO:Gradient Boosting Classifier Imported successfully
2024-10-29 13:47:24,589:INFO:Cross validation set to False
2024-10-29 13:47:24,589:INFO:Fitting Model
2024-10-29 13:47:24,978:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-29 13:47:24,978:INFO:create_model() successfully completed......................................
2024-10-29 13:47:25,212:INFO:Initializing create_model()
2024-10-29 13:47:25,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:25,212:INFO:Checking exceptions
2024-10-29 13:47:25,215:INFO:Importing libraries
2024-10-29 13:47:25,216:INFO:Copying training dataset
2024-10-29 13:47:25,221:INFO:Defining folds
2024-10-29 13:47:25,221:INFO:Declaring metric variables
2024-10-29 13:47:25,221:INFO:Importing untrained model
2024-10-29 13:47:25,221:INFO:Declaring custom model
2024-10-29 13:47:25,222:INFO:Extreme Gradient Boosting Imported successfully
2024-10-29 13:47:25,224:INFO:Cross validation set to False
2024-10-29 13:47:25,224:INFO:Fitting Model
2024-10-29 13:47:25,484:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...)
2024-10-29 13:47:25,485:INFO:create_model() successfully completed......................................
2024-10-29 13:47:25,745:INFO:Initializing create_model()
2024-10-29 13:47:25,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=71, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:25,746:INFO:Checking exceptions
2024-10-29 13:47:25,748:INFO:Importing libraries
2024-10-29 13:47:25,748:INFO:Copying training dataset
2024-10-29 13:47:25,753:INFO:Defining folds
2024-10-29 13:47:25,753:INFO:Declaring metric variables
2024-10-29 13:47:25,753:INFO:Importing untrained model
2024-10-29 13:47:25,753:INFO:Declaring custom model
2024-10-29 13:47:25,753:INFO:Random Forest Classifier Imported successfully
2024-10-29 13:47:25,755:INFO:Cross validation set to False
2024-10-29 13:47:25,755:INFO:Fitting Model
2024-10-29 13:47:25,892:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=71, verbose=0,
                       warm_start=False)
2024-10-29 13:47:25,892:INFO:create_model() successfully completed......................................
2024-10-29 13:47:26,079:INFO:Initializing create_model()
2024-10-29 13:47:26,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=71, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:26,079:INFO:Checking exceptions
2024-10-29 13:47:26,082:INFO:Importing libraries
2024-10-29 13:47:26,082:INFO:Copying training dataset
2024-10-29 13:47:26,085:INFO:Defining folds
2024-10-29 13:47:26,085:INFO:Declaring metric variables
2024-10-29 13:47:26,087:INFO:Importing untrained model
2024-10-29 13:47:26,087:INFO:Declaring custom model
2024-10-29 13:47:26,087:INFO:Extra Trees Classifier Imported successfully
2024-10-29 13:47:26,088:INFO:Cross validation set to False
2024-10-29 13:47:26,088:INFO:Fitting Model
2024-10-29 13:47:26,202:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=71, verbose=0,
                     warm_start=False)
2024-10-29 13:47:26,202:INFO:create_model() successfully completed......................................
2024-10-29 13:47:26,388:INFO:Initializing create_model()
2024-10-29 13:47:26,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=71, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:26,388:INFO:Checking exceptions
2024-10-29 13:47:26,390:INFO:Importing libraries
2024-10-29 13:47:26,390:INFO:Copying training dataset
2024-10-29 13:47:26,394:INFO:Defining folds
2024-10-29 13:47:26,394:INFO:Declaring metric variables
2024-10-29 13:47:26,394:INFO:Importing untrained model
2024-10-29 13:47:26,394:INFO:Declaring custom model
2024-10-29 13:47:26,394:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-29 13:47:26,396:INFO:Cross validation set to False
2024-10-29 13:47:26,396:INFO:Fitting Model
2024-10-29 13:47:26,419:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2024-10-29 13:47:26,419:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-10-29 13:47:26,419:INFO:[LightGBM] [Info] Total Bins 815
2024-10-29 13:47:26,419:INFO:[LightGBM] [Info] Number of data points in the train set: 472, number of used features: 8
2024-10-29 13:47:26,419:INFO:[LightGBM] [Info] Start training from score -1.166546
2024-10-29 13:47:26,419:INFO:[LightGBM] [Info] Start training from score -1.044991
2024-10-29 13:47:26,420:INFO:[LightGBM] [Info] Start training from score -1.088075
2024-10-29 13:47:26,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-10-29 13:47:26,535:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=71, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-10-29 13:47:26,535:INFO:create_model() successfully completed......................................
2024-10-29 13:47:26,763:INFO:_master_model_container: 15
2024-10-29 13:47:26,763:INFO:_display_container: 2
2024-10-29 13:47:26,766:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='multi:softprob', ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=71, verbose=0,
                       warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=71, verbose=0,
                     warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=71, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2024-10-29 13:47:26,768:INFO:compare_models() successfully completed......................................
2024-10-29 13:47:45,551:INFO:Initializing tune_model()
2024-10-29 13:47:45,552:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>)
2024-10-29 13:47:45,552:INFO:Checking exceptions
2024-10-29 13:47:45,567:INFO:Copying training dataset
2024-10-29 13:47:45,571:INFO:Checking base model
2024-10-29 13:47:45,571:INFO:Base model : Gradient Boosting Classifier
2024-10-29 13:47:45,576:INFO:Declaring metric variables
2024-10-29 13:47:45,579:INFO:Defining Hyperparameters
2024-10-29 13:47:45,811:INFO:Tuning with n_jobs=-1
2024-10-29 13:47:45,811:INFO:Initializing RandomizedSearchCV
2024-10-29 13:47:52,558:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2024-10-29 13:47:52,559:INFO:Hyperparameter search completed
2024-10-29 13:47:52,559:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:52,560:INFO:Initializing create_model()
2024-10-29 13:47:52,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B0F9E34D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.9, 'n_estimators': 80, 'min_samples_split': 10, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 'log2', 'max_depth': 6, 'learning_rate': 0.05})
2024-10-29 13:47:52,560:INFO:Checking exceptions
2024-10-29 13:47:52,560:INFO:Importing libraries
2024-10-29 13:47:52,561:INFO:Copying training dataset
2024-10-29 13:47:52,565:INFO:Defining folds
2024-10-29 13:47:52,565:INFO:Declaring metric variables
2024-10-29 13:47:52,568:INFO:Importing untrained model
2024-10-29 13:47:52,568:INFO:Declaring custom model
2024-10-29 13:47:52,572:INFO:Gradient Boosting Classifier Imported successfully
2024-10-29 13:47:52,577:INFO:Starting cross validation
2024-10-29 13:47:52,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:53,308:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,309:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,312:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,314:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,321:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,323:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,327:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,330:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,335:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,337:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,340:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,344:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,345:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,346:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,348:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,349:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,350:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,353:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,354:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,354:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,355:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,355:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,358:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,361:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,365:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,366:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,369:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,369:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,370:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,371:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,372:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,372:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,373:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,373:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,376:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,379:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,389:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:53,391:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,393:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,394:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:53,400:INFO:Calculating mean and std
2024-10-29 13:47:53,401:INFO:Creating metrics dataframe
2024-10-29 13:47:53,407:INFO:Finalizing model
2024-10-29 13:47:53,851:INFO:Uploading results into container
2024-10-29 13:47:53,852:INFO:Uploading model into container now
2024-10-29 13:47:53,852:INFO:_master_model_container: 16
2024-10-29 13:47:53,852:INFO:_display_container: 3
2024-10-29 13:47:53,853:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-29 13:47:53,853:INFO:create_model() successfully completed......................................
2024-10-29 13:47:54,052:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:54,052:INFO:choose_better activated
2024-10-29 13:47:54,055:INFO:SubProcess create_model() called ==================================
2024-10-29 13:47:54,055:INFO:Initializing create_model()
2024-10-29 13:47:54,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:47:54,055:INFO:Checking exceptions
2024-10-29 13:47:54,058:INFO:Importing libraries
2024-10-29 13:47:54,058:INFO:Copying training dataset
2024-10-29 13:47:54,061:INFO:Defining folds
2024-10-29 13:47:54,061:INFO:Declaring metric variables
2024-10-29 13:47:54,061:INFO:Importing untrained model
2024-10-29 13:47:54,061:INFO:Declaring custom model
2024-10-29 13:47:54,061:INFO:Gradient Boosting Classifier Imported successfully
2024-10-29 13:47:54,062:INFO:Starting cross validation
2024-10-29 13:47:54,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-29 13:47:54,684:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,686:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,687:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,688:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,690:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,691:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,692:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,693:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,693:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,695:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,698:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,699:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,699:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,701:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,701:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,701:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,701:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,702:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,705:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,705:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,706:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,706:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,708:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,708:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,709:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,709:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,711:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,712:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,713:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,714:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,714:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,715:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-29 13:47:54,715:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,716:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,717:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,717:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,718:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,718:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,719:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,720:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:47:54,726:INFO:Calculating mean and std
2024-10-29 13:47:54,726:INFO:Creating metrics dataframe
2024-10-29 13:47:54,728:INFO:Finalizing model
2024-10-29 13:47:55,144:INFO:Uploading results into container
2024-10-29 13:47:55,144:INFO:Uploading model into container now
2024-10-29 13:47:55,144:INFO:_master_model_container: 17
2024-10-29 13:47:55,145:INFO:_display_container: 4
2024-10-29 13:47:55,145:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-29 13:47:55,145:INFO:create_model() successfully completed......................................
2024-10-29 13:47:55,331:INFO:SubProcess create_model() end ==================================
2024-10-29 13:47:55,332:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=71, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7477
2024-10-29 13:47:55,332:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7541
2024-10-29 13:47:55,332:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-10-29 13:47:55,332:INFO:choose_better completed
2024-10-29 13:47:55,340:INFO:_master_model_container: 17
2024-10-29 13:47:55,341:INFO:_display_container: 3
2024-10-29 13:47:55,342:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-29 13:47:55,342:INFO:tune_model() successfully completed......................................
2024-10-29 13:49:09,425:INFO:Initializing predict_model()
2024-10-29 13:49:09,425:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002B0FBE8D820>)
2024-10-29 13:49:09,425:INFO:Checking exceptions
2024-10-29 13:49:09,425:INFO:Preloading libraries
2024-10-29 13:49:09,519:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:49:09,522:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:49:09,524:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:49:22,101:INFO:Initializing finalize_model()
2024-10-29 13:49:22,101:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-10-29 13:49:22,103:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-29 13:49:22,104:INFO:Initializing create_model()
2024-10-29 13:49:22,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=3,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=80, n_iter_no_change=None,
                           random_state=71, subsample=0.9, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-10-29 13:49:22,104:INFO:Checking exceptions
2024-10-29 13:49:22,106:INFO:Importing libraries
2024-10-29 13:49:22,106:INFO:Copying training dataset
2024-10-29 13:49:22,106:INFO:Defining folds
2024-10-29 13:49:22,106:INFO:Declaring metric variables
2024-10-29 13:49:22,106:INFO:Importing untrained model
2024-10-29 13:49:22,106:INFO:Declaring custom model
2024-10-29 13:49:22,107:INFO:Gradient Boosting Classifier Imported successfully
2024-10-29 13:49:22,108:INFO:Cross validation set to False
2024-10-29 13:49:22,108:INFO:Fitting Model
2024-10-29 13:49:22,590:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'plasma_CA19_9',
                                             'creatinine', 'LYVE1', 'REG1B',
                                             'TFF1', 'REG1A'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.05, loss='log_loss',
                                            max_depth=6, max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0005,
                                            min_samples_leaf=3,
                                            min_samples_split=10,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=80,
                                            n_iter_no_change=None,
                                            random_state=71, subsample=0.9,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-10-29 13:49:22,591:INFO:create_model() successfully completed......................................
2024-10-29 13:49:22,768:INFO:_master_model_container: 17
2024-10-29 13:49:22,768:INFO:_display_container: 4
2024-10-29 13:49:22,780:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'plasma_CA19_9',
                                             'creatinine', 'LYVE1', 'REG1B',
                                             'TFF1', 'REG1A'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.05, loss='log_loss',
                                            max_depth=6, max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0005,
                                            min_samples_leaf=3,
                                            min_samples_split=10,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=80,
                                            n_iter_no_change=None,
                                            random_state=71, subsample=0.9,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-10-29 13:49:22,780:INFO:finalize_model() successfully completed......................................
2024-10-29 13:49:23,008:INFO:Initializing save_model()
2024-10-29 13:49:23,008:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'plasma_CA19_9',
                                             'creatinine', 'LYVE1', 'REG1B',
                                             'TFF1', 'REG1A'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.05, loss='log_loss',
                                            max_depth=6, max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0005,
                                            min_samples_leaf=3,
                                            min_samples_split=10,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=80,
                                            n_iter_no_change=None,
                                            random_state=71, subsample=0.9,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=pancreas_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\arunm\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'plasma_CA19_9',
                                             'creatinine', 'LYVE1', 'REG1B',
                                             'TFF1', 'REG1A'],
                                    transformer=SimpleImputer(add_ind...
                                    transformer=OrdinalEncoder(cols=['sex'],
                                                               drop_invariant=False,
                                                               handle_missing='return_nan',
                                                               handle_unknown='value',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-10-29 13:49:23,009:INFO:Adding model into prep_pipe
2024-10-29 13:49:23,009:WARNING:Only Model saved as it was a pipeline.
2024-10-29 13:49:23,036:INFO:pancreas_pipeline.pkl saved in current working directory
2024-10-29 13:49:23,051:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'plasma_CA19_9',
                                             'creatinine', 'LYVE1', 'REG1B',
                                             'TFF1', 'REG1A'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.05, loss='log_loss',
                                            max_depth=6, max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0005,
                                            min_samples_leaf=3,
                                            min_samples_split=10,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=80,
                                            n_iter_no_change=None,
                                            random_state=71, subsample=0.9,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-10-29 13:49:23,052:INFO:save_model() successfully completed......................................
2024-10-29 13:49:23,281:INFO:Initializing predict_model()
2024-10-29 13:49:23,281:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0FBB9F400>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'plasma_CA19_9',
                                             'creatinine', 'LYVE1', 'REG1B',
                                             'TFF1', 'REG1A'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.05, loss='log_loss',
                                            max_depth=6, max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0005,
                                            min_samples_leaf=3,
                                            min_samples_split=10,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=80,
                                            n_iter_no_change=None,
                                            random_state=71, subsample=0.9,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002B0F47C4E50>)
2024-10-29 13:49:23,281:INFO:Checking exceptions
2024-10-29 13:49:23,281:INFO:Preloading libraries
2024-10-29 13:49:23,370:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:49:23,372:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 13:49:23,374:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-29 14:39:16,220:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\interpret\glassbox\_ebm\_ebm.py:740: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]
  warn(

2024-10-29 14:39:19,456:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\interpret\glassbox\_ebm\_ebm.py:999: UserWarning: Detected multiclass problem. Forcing interactions to 0. Multiclass interactions only have local explanations. They are not currently displayed in the global explanation visualizations. Set interactions=0 to disable this warning. If you still want multiclass interactions, this API accepts a list, and the measure_interactions function can be used to detect them.
  warn(

2024-10-29 14:42:57,319:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\optuna\distributions.py:704: UserWarning:

The distribution is specified by [4, 256] and step=8, but the range is not divisible by `step`. It will be replaced by [4, 252].


2024-10-29 14:57:11,279:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\kan\MultKAN.py:798: UserWarning:

std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\ReduceOps.cpp:1808.)


2024-10-29 14:57:11,279:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\kan\MultKAN.py:808: UserWarning:

std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\ReduceOps.cpp:1808.)


2024-10-29 14:57:11,279:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\kan\MultKAN.py:809: UserWarning:

std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\ReduceOps.cpp:1808.)


2024-10-29 14:57:11,279:WARNING:c:\Users\arunm\.conda\envs\arun\lib\site-packages\kan\MultKAN.py:810: UserWarning:

std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\ReduceOps.cpp:1808.)


